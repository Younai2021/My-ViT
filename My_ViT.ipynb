{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de34ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70c435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af58c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81611270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer 里面的MLP \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        # PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "        # dim = 1024,   mlp_dim = 2048,dropout = 0.1,\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim), \n",
    "            nn.Dropout(dropout)\n",
    "        ) # 1024-> 2048 -> GELU-> Dropout->1024->Dropout--->>1024\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ded9c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "class Attention(nn.Module):              \n",
    "    def __init__(self, dim, heads=8, dim_head=64, dropout=0.):\n",
    "        # dim = 1024,   depth = 6,heads = 16, dim_head=64,  mlp_dim = 2048,dropout = 0.1,\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout),\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)           # (b, n(65), dim*3) ---> 3 * (b, n, dim)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)          # q, k, v   (b, h, n, dim_head(64))\n",
    "\n",
    "        dots = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7e0271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout=0.):\n",
    "        # dim = 1024,   depth = 6,heads = 16, dim_head=64,  mlp_dim = 2048,dropout = 0.1,\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth): # depth = 6\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Attention(dim, heads=heads, dim_head=dim_head, dropout=dropout)), # 先norm，再算Attention\n",
    "                PreNorm(dim, FeedForward(dim, mlp_dim, dropout=dropout))\n",
    "            ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x # 加上残差\n",
    "            x = ff(x) + x   # 加上残差\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf17c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, \\\n",
    "                 mlp_dim, pool='cls', channels=3, dim_head=64, dropout=0., emb_dropout=0.):\n",
    "        '''\n",
    "        image_size = 256,\n",
    "        patch_size = 32,\n",
    "        num_classes = 1000,\n",
    "        dim = 1024,\n",
    "        depth = 6,\n",
    "        heads = 16,\n",
    "        mlp_dim = 2048,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "        '''\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size) # 图片是256*256\n",
    "        patch_height, patch_width = pair(patch_size) #patch is 32*32\n",
    "\n",
    "        assert  image_height % patch_height ==0 and image_width % patch_width == 0 # 保证可以整除\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width) # patch个数=64\n",
    "        print(num_patches)\n",
    "        patch_dim = channels * patch_height * patch_width # patch_dim = 3*32*32 =  3,072\n",
    "        assert pool in {'cls', 'mean'}\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=patch_height, p2=patch_width),\n",
    "            nn.Linear(patch_dim, dim) # 改变patch 维度 到dim=1024\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\t\t\t\t\t# nn.Parameter()定义可学习参数\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "        # dim = 1024,   depth = 6,heads = 16, dim_head=64,  mlp_dim = 2048,dropout = 0.1,\n",
    "        self.pool = pool # pool='cls'\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes) # 1024--->num_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)        # b c (h p1) (w p2) -> b (h w) (p1 p2 c) -> b (h w) dim\n",
    "        b, n, _ = x.shape           # b表示batchSize, n表示每个块的空间分辨率就是patch的个数, _表示一个块内有多少个值\n",
    "        print('n is:',n)\n",
    "        print('_ is:',_)\n",
    "        # repeat() 复制并增添维度\n",
    "        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b=b) \n",
    "        # self.cls_token是要操作的tensor名，这一行的目的是把self.cls_token复制为batchsize的个数\n",
    "        # b是batchsize = 16，后面的n，d不变， cls_token是（1,1，dim）\n",
    "        # self.cls_token: (1, 1, dim) -> cls_tokens: (batchSize, 1, dim)  \n",
    "        x = torch.cat((cls_tokens, x), dim=1)               # 将cls_token拼接到patch token中去       (b, 65, dim)\n",
    "        print('pos_embedding[:, :(n+1)] is:\\n',self.pos_embedding[:, :(n+1)] )\n",
    "        print('pos_embedding[:, :(n+1)] shape is:\\n',self.pos_embedding[:, :(n+1)].shape )\n",
    "        x = x + self.pos_embedding[:, :(n+1)]                  # 加位置嵌入（直接加）      (b, 65, dim)\n",
    "        x = self.dropout(x) # x中的一部分值会被随机变为零，这个只能在训练的时候用\n",
    "\n",
    "        x = self.transformer(x)                                                 # (b, 65, dim)\n",
    "        print(\"x after transformer:\\n\",x)\n",
    "        print(\"x.shape after transformer:\\n\",x.shape)\n",
    "        # self.pool == 'cls'\n",
    "        x = x.mean(dim=1) if self.pool == 'mean' else x[:, 0]                   # (b, dim) # 只取65个patch中的序号为0的一个也就是cls\n",
    "\n",
    "        x = self.to_latent(x)                                                   # Identity (b, dim) # 不变，只是占位\n",
    "        print('取65个patch中的序号为0的一个也就是cls:',x.shape)\n",
    "\n",
    "        return self.mlp_head(x)                                                 #  (b, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "557fe573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "n is: 64\n",
      "_ is: 1024\n",
      "pos_embedding[:, :(n+1)] is:\n",
      " tensor([[[-0.3722,  0.3396,  1.4037,  ..., -0.4461, -0.7364,  0.2433],\n",
      "         [ 1.4336,  1.9588, -0.2457,  ...,  0.7117, -0.2338,  0.3758],\n",
      "         [ 0.5752,  0.3203,  0.2581,  ...,  0.3693, -0.2199,  1.1205],\n",
      "         ...,\n",
      "         [-1.3470,  0.5339,  1.1822,  ...,  1.0060, -1.1918, -0.4994],\n",
      "         [-0.8746, -0.4046, -0.1143,  ..., -0.7404, -1.5288, -1.5283],\n",
      "         [ 1.2498, -0.3553,  0.9992,  ...,  0.0915,  0.0025, -1.6904]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "pos_embedding[:, :(n+1)] shape is:\n",
      " torch.Size([1, 65, 1024])\n",
      "x after transformer:\n",
      " tensor([[[-1.4542,  1.1076,  0.7253,  ..., -0.4778, -0.4722, -0.0113],\n",
      "         [ 1.3191,  2.0528, -0.6181,  ..., -0.1488, -1.1117, -0.0330],\n",
      "         [-0.3973,  0.1895,  0.4334,  ...,  0.2784, -0.6314,  2.3400],\n",
      "         ...,\n",
      "         [-0.8121, -0.3650,  1.3722,  ..., -0.1010, -0.9574,  0.6822],\n",
      "         [-1.2663, -0.9729, -0.5192,  ..., -1.2287, -1.3402, -2.4660],\n",
      "         [ 2.0645,  1.4156,  0.0693,  ...,  0.1319,  0.2686, -2.7767]],\n",
      "\n",
      "        [[-0.8677,  0.9801,  0.5805,  ..., -0.5080,  0.2100, -0.4649],\n",
      "         [ 0.7893, -0.0709, -1.2123,  ...,  0.6732, -0.6221, -0.9468],\n",
      "         [ 0.4260,  0.5207,  0.7887,  ..., -0.6000,  0.2517,  1.1586],\n",
      "         ...,\n",
      "         [-1.8033,  1.1354,  1.7853,  ...,  0.0636, -2.4034, -1.8189],\n",
      "         [-2.8129, -0.0553,  1.2547,  ..., -0.9878, -1.9957, -1.9026],\n",
      "         [ 0.1391, -0.9433,  1.7603,  ..., -0.7352, -1.6274, -2.1459]],\n",
      "\n",
      "        [[-0.9505,  0.9472,  0.3419,  ..., -0.0065, -0.1459, -0.1620],\n",
      "         [ 0.0545,  1.2106,  0.1742,  ...,  2.6936, -0.7081, -0.4346],\n",
      "         [ 0.8890,  1.4752,  0.9309,  ...,  0.4436,  1.2508,  1.9487],\n",
      "         ...,\n",
      "         [-2.0635,  0.1589,  1.5865,  ...,  0.5243, -0.6536, -0.4682],\n",
      "         [-0.6089, -2.2592,  0.0712,  ..., -0.8989, -0.7642, -1.0205],\n",
      "         [ 1.9465,  0.4488,  0.1687,  ...,  1.1801,  0.3595, -2.5071]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6315,  1.4726,  0.6172,  ..., -0.3981, -0.1244, -0.2850],\n",
      "         [ 2.4737,  1.3950,  0.0521,  ...,  0.9610,  0.3394, -0.0332],\n",
      "         [-0.1185, -0.8823,  1.3282,  ..., -0.0099, -1.0797,  0.5707],\n",
      "         ...,\n",
      "         [-1.5233,  0.5302,  0.8373,  ..., -0.0993, -2.3296, -1.9767],\n",
      "         [-1.9854, -0.4200, -1.6510,  ..., -0.6228, -1.2167, -2.2299],\n",
      "         [ 0.6141, -1.1000,  0.5553,  ..., -1.1408, -0.3636, -2.3095]],\n",
      "\n",
      "        [[ 0.3321,  1.4886,  0.9411,  ..., -0.8124, -0.2462, -0.1925],\n",
      "         [ 1.3424,  0.8184, -0.0394,  ..., -0.3021, -0.2564,  0.4473],\n",
      "         [ 1.8512, -1.4254,  0.1881,  ...,  1.2432, -1.1512,  1.9786],\n",
      "         ...,\n",
      "         [-2.4946, -0.4803,  0.4704,  ...,  1.2280, -1.4271, -0.8994],\n",
      "         [-0.7231,  0.7336,  0.6671,  ...,  0.0579, -2.0586, -0.5576],\n",
      "         [ 2.9279,  0.3113,  0.5121,  ...,  0.6923, -0.1414, -4.3728]],\n",
      "\n",
      "        [[-1.6284,  1.6246,  1.3909,  ..., -0.4850, -0.3874, -0.2718],\n",
      "         [ 2.5580,  2.2426, -0.5800,  ...,  0.3228, -0.8449, -1.1406],\n",
      "         [-0.7355, -0.5566, -0.4796,  ...,  1.3536, -0.3665, -1.0771],\n",
      "         ...,\n",
      "         [-0.9252,  0.8016,  2.1259,  ...,  0.9767, -0.4510,  0.2414],\n",
      "         [-0.4991, -1.0321,  0.0844,  ..., -0.4647, -1.7130, -1.4487],\n",
      "         [ 0.5010, -0.0722,  0.9824,  ..., -0.1446, -0.2375, -1.9715]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "x.shape after transformer:\n",
      " torch.Size([16, 65, 1024])\n",
      "取65个patch中的序号为0的一个也就是cls: torch.Size([16, 1024])\n",
      "torch.Size([16, 1000])\n"
     ]
    }
   ],
   "source": [
    "model_vit = ViT(\n",
    "        image_size = 256,\n",
    "        patch_size = 32,\n",
    "        num_classes = 1000,\n",
    "        dim = 1024,\n",
    "        depth = 6,\n",
    "        heads = 16,\n",
    "        mlp_dim = 2048,\n",
    "        dropout = 0.1,\n",
    "        emb_dropout = 0.1\n",
    "    )\n",
    "\n",
    "img = torch.randn(16, 3, 256, 256) # （图片数，3通道，256*256）\n",
    "\n",
    "preds = model_vit(img) \n",
    "\n",
    "print(preds.shape)  # (16, 1000) # 1000是输出类别个数1000个\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd354f26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae4cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38266e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
